[{"id":25,"url":"/doc/ros2/Tutorials/Cross-compilation/","title":"Cross-Compilation","content":"\nCross-Compilation¶\n\nTable of Contents\n\nOverview\nHow does it work ?\nCross-compiling ROS2\n\nCMake toolchain-file\nTarget file-system\nBuild process\n\n\nCross-compiling examples for Arm\n\n1. Install development tools\n2. Download ROS2 source code\n3. Prepare the sysroot\n4. Build\n\n\nAutomated Cross-compilation\nCross-compiling against a pre-built ROS2\nRun on the target\n\n\n\nOverview¶\n\nOpen Robotics provides pre-built ROS2 packages for multiple platforms, but a number of developers still rely on cross-compilation for different reasons such as:\nThe development machine does not match the target system.\nTuning the build for specific core architecture (e.g. setting -mcpu=cortex-a53 -mfpu=neon-fp-armv8 when building for Raspberry Pi3).\nTargeting a different file systems other than the ones supported by the pre-built images released by Open Robotics.\n\n\n\nThis document provides you with details on how to cross-compile the ROS2 software stack as well as provide examples for cross-compiling to systems based on the Arm cores.\n\nNote\nThere are a few ROS2 packages that fail cross-compilation and have to be disabled during the build. See 4. Build section.\n\n\n\nHow does it work ?¶\nCross-compiling simple software (e.g. no dependencies on external libraries) is relatively simple and only requiring a cross-compiler toolchain to be used instead of the native toolchain.\n\nThere are a number of factors which make this process more complex:\nThe software being built must support the target architecture. Architecture specific code must be properly isolated and enabled during the build according to the target architecture. Examples include assembly code.\nAll dependencies (e.g. libraries) must be present, either as pre-built packages or also cross-compiled before the target software using them is cross-compiled.\nWhen building software stacks (as opposed to an standalone software) using build tools (e.g. colcon), it is expected from the build tool a mechanism to allow the developer to enable cross-compilation on the underlying build system used by each of software in the stack.\n\n\n\n\n\nCross-compiling ROS2¶\n\nAlthough ROS2 is a rich software stack with a number of dependencies, it primarily uses two different types of packages:\nPython based software, which requires no cross-compilation.\nCMake based software, which provides a mechanism to do cross-compilation.\n\n\n\nFurthermore, the ROS2 software stack is built with Colcon which provides a mechanism to forward parameters to the CMake instance used for the individual build of each package/library that is part of the ROS2 distribution.\nWhen building ROS2 natively, the developer is required to download all the dependencies (e.g. Python and other libraries) before compiling the packages that are part of the ROS2 distribution. When cross-compiling, the same approach is required. The developer must first have the target system’s filesystem with all dependencies already installed.\nThe next sections of this document explain in detail the use of cmake-toolchains and the CMAKE_SYSROOT feature to cross-compile ROS2.\n\nCMake toolchain-file¶\nA CMake toolchain-file is a file which defines variables to configure CMake for cross-compilation. The basic entries are:\n\n\nCMAKE_SYSTEM_NAME: the target platform, e.g. linux\nCMAKE_SYSTEM_PROCESSOR: the target architecture, e.g. aarch64 or arm\nCMAKE_SYSROOT: the path to the target file-system\nCMAKE_C_COMPILER: the C cross-compiler, e.g. aarch64-linux-gnu-gcc\nCMAKE_CXX_COMPILER: the C++ cross-compiler, e.g. aarch64-linux-gnu-g++\nCMAKE_FIND_ROOT_PATH: an alternative path used by the find_* command to find the file-system\n\n\nWhen cross-compiling ROS2, the following options are required to be set:\n\n\nCMAKE_FIND_ROOT_PATH: the alternative path used by the find_* command, use it to specify the path to ROS2 /install folder\nCMAKE_FIND_ROOT_PATH_MODE_*: the search strategy for program,package,library, and include, usually: NEVER (look on the host-fs), ONLY (look on sysroot), ONLY (look on sysroot) and ONLY (look on sysroot)\nPYTHON_SOABI: the index name of the python libraries generated by ROS2, e.g. cpython-36m-aarch64-linux-gnu\nTHREADS_PTHREAD_ARG \"0\" CACHE STRING \"Result from TRY_RUN\" FORCE: Force the result of the TRY_RUN cmd to 0 (success) because binaries can not run on the host system.\n\n\nThe toolchain-file is provided to CMake with the -DCMAKE_TOOLCHAIN_FILE=path/to/file parameter. This will also set the CMAKE_CROSSCOMPILING variable to true which can be used by the software being built.\nThe CMAKE_SYSROOT is particularly important for ROS2 as the packages need many dependencies (e.g. python, openssl, opencv, poco, eigen3, …).\nSetting CMAKE_SYSROOT to a target file-system with all the dependencies installed on it will allow CMake to find them during the cross-compilation.\n\nNote\nYou can find more information on the CMake documentation page.\n\nWhen dowloading the ROS2 source code, a generic toolchain-file is available in the repository ros2/cross_compile/cmake-toolchains which can be downloaded separately. Further examples on using it can be found on the Cross-compiling examples for Arm section.\n\n\nTarget file-system¶\nAs mentioned previously, ROS2 requires different libraries which needs to be provided to cross-compile.\n\nThere are a number of ways to obtain the file-system:\ndownloading a pre-built image\ninstalling the dependencies on the target and exporting the file-system (e.g. with sshfs)\nusing qemu + docker (or chroot) to generate the file-system on the host machine.\n\n\n\n\nNote\nYou can find information on how to use Docker + qemu on the next Cross-compiling examples for Arm section.\n\n\n\nBuild process¶\nThe build process is similar to native compilation. The only difference is an extra argument to Colcon to specify the toolchain-file:\ncolcon build --merge-install \\\n    --cmake-force-configure \\\n    --cmake-args \\\n        -DCMAKE_TOOLCHAIN_FILE=\"<path_to_toolchain/toolchainfile.cmake>\"\n\n\nThe toolchain-file provide to CMake the information of the cross-compiler and the target file-system.\nColcon will call CMake with the given toolchain-file on every package of ROS2.\n\n\n\nCross-compiling examples for Arm¶\nAfter downloading the ROS2 source code, you can add cross-compilation assets to the workspace via git clone https://github.com/ros2/cross_compile.git src/ros2/cross_compile. These are working examples on how to cross-compile for Arm cores.\n\nThe following targets are supported:\nUbuntu-arm64: To be used with any ARMv8-A based system.\nUbuntu-armhf: To be used with any modern ARMv7-A based system.\n\n\nThese are the main steps:\nInstalling development tools\nDownloading ROS2 source code\nDownloading the ROS2 cross-compilation assets\nPreparing the sysroot\nCross-compiling the ROS2 software stack\n\n\n\nThe next sections explains in detail each of these steps.\nFor a quick-setup, have a look at the Automated Cross-compilation.\n\nNote\nThese steps were tested on an Ubuntu 18.04 (Bionic)\n\n\n1. Install development tools¶\nThis step is similar to when building natively. The difference is that some of the libraries and tools are not required because they will be in the sysroot instead.\nThe following packages are required\nsudo apt update && sudo apt install -y \\\n    cmake \\\n    git \\\n    wget \\\n    python3-pip \\\n    qemu-user-static \\\n    g++-aarch64-linux-gnu \\\n    g++-arm-linux-gnueabihf \\\n    pkg-config-aarch64-linux-gnu\n\npython3 -m pip install -U \\\n    vcstool \\\n    colcon-common-extensions\n\n\n\nNote\nYou can install vcstool and colcon-common-extensions via pip. This\nmeans you are not required to add extra apt repositories.\n\nDocker is used to build the target environment. Follow the official documentation for the installation.\n\n\n2. Download ROS2 source code¶\nThen create a workspace and download the ROS2 source code:\nmkdir -p ~/cc_ws/ros2_ws/src\ncd ~/cc_ws/ros2_ws\nwget https://raw.githubusercontent.com/ros2/ros2/release-latest/ros2.repos\nvcs-import src < ros2.repos\ngit clone https://github.com/ros2/cross_compile.git src/ros2/cross_compile\ncd ..\n\n\n\n\n3. Prepare the sysroot¶\nBuild an arm Ubuntu image with all the ROS2 dependencies using Docker and qemu:\nCopy the qemu-static binary to the workspace.\nIt will be used to install the ros2 dependencies on the target file-system with docker.\nmkdir qemu-user-static\ncp /usr/bin/qemu-*-static qemu-user-static\n\n\nThe standard setup process of ROS2 is run inside an arm docker. This is possible thanks to qemu-static, which will emulate an arm machine. The base image used is an Ubuntu Bionic from Docker Hub.\ndocker build -t arm_ros2:latest -f ros2_ws/src/ros2/cross_compile/sysroot/Dockerfile_ubuntu_arm .\ndocker run --name arm_sysroot arm_ros2:latest\n\n\nExport the resulting container to a tarball and extract it:\ndocker container export -o sysroot_docker.tar arm_sysroot\nmkdir sysroot_docker\ntar -C sysroot_docker -xf sysroot_docker.tar lib usr opt etc\ndocker rm arm_sysroot\n\n\nThis container can be used later as virtual target to run the created file-system and run the demo code.\n\n\n4. Build¶\nSet the variables used by the generic toolchain-file\nexport TARGET_ARCH=aarch64\nexport TARGET_TRIPLE=aarch64-linux-gnu\nexport CC=/usr/bin/$TARGET_TRIPLE-gcc\nexport CXX=/usr/bin/$TARGET_TRIPLE-g++\nexport CROSS_COMPILE=/usr/bin/$TARGET_TRIPLE-\nexport SYSROOT=~/cc_ws/sysroot_docker\nexport ROS2_INSTALL_PATH=~/cc_ws/ros2_ws/install\nexport PYTHON_SOABI=cpython-36m-$TARGET_TRIPLE\n\n\nThe following packages still cause errors during the cross-compilation (under investigation) and must be disabled for now.\ntouch \\\n    ros2_ws/src/ros2/rviz/COLCON_IGNORE \\\n    ros2_ws/src/ros-visualization/COLCON_IGNORE\n\n\nThe Poco pre-built has a known issue where it is searching for libz and libpcre on the host system instead of SYSROOT.\nAs a workaround for the moment, please link both libraries into the the host’s file-system.\nmkdir -p /usr/lib/$TARGET_TRIPLE\nln -s `pwd`/sysroot_docker/lib/$TARGET_TRIPLE/libz.so.1 /usr/lib/$TARGET_TRIPLE/libz.so\nln -s `pwd`/sysroot_docker/lib/$TARGET_TRIPLE/libpcre.so.3 /usr/lib/$TARGET_TRIPLE/libpcre.so\n\n\nThen, start a build with colcon specifying the toolchain-file:\ncd ros2_ws\n\ncolcon build --merge-install \\\n    --cmake-force-configure \\\n    --cmake-args \\\n        -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \\\n        -DCMAKE_TOOLCHAIN_FILE=\"$(pwd)/src/ros2/cross_compile/cmake-toolchains/generic_linux.cmake\" \\\n        -DSECURITY=ON\n\n\nDone! The install and build directories will contain the cross-compiled assets.\n\n\n\nAutomated Cross-compilation¶\nAll the steps above are also included into a Dockerfile and can be used for automation/CI.\nFirst, download the dockerfile and build the image:\nwget https://raw.githubusercontent.com/ros2/cross_compile/master/Dockerfile_cc_for_arm\ndocker build -t ros2-crosscompiler:latest - < Dockerfile_cc_for_arm\n\n\nNow run the image with:\n(it will take a while !)\ndocker run -it --name ros2_cc \\\n    -v /var/run/docker.sock:/var/run/docker.sock \\\n    ros2-crosscompiler:latest\n\n\n..note:: The -v /var/run/docker.sock allow us to use Docker inside Docker.\nThe result of the build will be inside the ros2_ws directory, which can be exported with:\ndocker cp ros2_cc:/root/cc_ws/ros2_ws .\n\n\n\n\nCross-compiling against a pre-built ROS2¶\nIt is possible to cross-compile your packages against a pre-built ROS2. The steps are similar to the previous Cross-compiling examples for Arm section, with the following modifications:\nInstead of downloading the ROS2 stack, just populate your workspace with your package (ros2 examples on this case) and the cross-compilation assets:\nmkdir -p ~/cc_ws/ros2_ws/src\ncd ~/cc_ws/ros2_ws/src\ngit clone https://github.com/ros2/examples.git\ngit clone https://github.com/ros2/cross_compile.git\ncd ..\n\n\nGenerate and export the file-system as described in 3. Prepare the sysroot, but with the provided Dockerfile_ubuntu_arm64_prebuilt. These _prebuilt Dockerfile will use the binary packages to install ROS2 instead of building from source.\nModify the environment variable ROS2_INSTALL_PATH to point to the installation directory:\nexport ROS2_INSTALL_PATH=~/cc_ws/sysroot_docker/opt/ros/crystal\n\n\nSource the setup.bash script on the target file-system:\nsource $ROS2_INSTALL_PATH/setup.bash\n\n\nThen, start a build with Colcon specifying the toolchain-file:\ncolcon build \\\n    --merge-install \\\n    --cmake-force-configure \\\n    --cmake-args \\\n        -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \\\n        -DCMAKE_TOOLCHAIN_FILE=\"$(pwd)/src/cross_compile/cmake-toolchains/generic_linux.cmake\"\n\n\n\n\nRun on the target¶\nCopy the file-system on your target or use the previously built docker image:\ndocker run -it --rm -v `pwd`/ros2_ws:/ros2_ws arm_ros2:latest\n\n\nSource the environment:\nsource /ros2_ws/install/local_setup.bash\n\n\nRun some of the C++ or python examples:\nros2 run demo_nodes_cpp listener &\nros2 run demo_nodes_py talker\n\n\n\n\n"},{"id":26,"url":"/doc/ros2/Tutorials/Defining-custom-interfaces-(msg-srv)/","title":"Defining custom interfaces (msg/srv)","content":"\nDefining custom interfaces (msg/srv)¶\nINCOMPLETE\nWhile we encourage reuse of existing “standard” message and service definitions wherever possible, there are plenty of cases in which you’ll need to define your own custom messages and/or services for a particular application.\nThe first step in defining a custom message or service is to write the .msg or .srv file, which you do using the ROS interface definition language.\nBy convention, .msg files go into a package subdirectory called msg and .srv files go into a package subdirectory called srv (you can pick different locations, but we recommend following the convention).\nHaving written your .msg and/or .srv files, you need to add some code to your package’s CMakelists.txt file to make the code generators run over your definitions. In lieu of a more complete tutorial on this topic, consult the pendulum_msgs package as an example. You can see the relevant CMake calls in that packages’s CMakeLists.txt file.\nNote that the package.xml format must equal 3 for this to build, this is because the member_of_group command requires format 3. ROS2’s create package generates the package.xml with a default format of 2.\n\n"},{"id":27,"url":"/doc/ros2/Contributing/Design-Guide/","title":"Design Guide: Common patterns in ROS 2","content":"\nDesign Guide: Common patterns in ROS 2¶\n\nComposable nodes as shared libraries¶\nContext\nYou want to export composable nodes as a shared libraries from some packages and using those in another package that does link-time composition.\nSolution\n\nAdd code to the CMake file which imports the actual targets in downstream packages\n\nInstall the generated file\nExport the generated file\n\n\n\nExample\nROS Discourse - Ament best practice for sharing libraries\n\n\nFastRTPS large data transfer¶\nContext\nYou want to transfer large data via FastRTPS.\nProblem\nDDS/RTPS uses UDP with a maximum message size of 64k\nSolution\nConfigure the middleware that it fragements large data into messages\nImplementation\nUse Asynchronous publication mode:\n<publishMode>\n  <kind>ASYNCHRONOUS</kind>\n</publishMode>\n\n\nROS2 Fine Tuning\n\n\nFastRTPS Best Effort Video Streaming¶\nContext\nYou want to transfer video streams and provide up to date data. It is ok to loose some packages.\nProblem\nAcknowledged data transmission mechanisms prevent from being able to provide\nup to date packages.\nSolution\nUse “best effort” communication (instead of the usual acknowledgement based\nmechanism) and prioritize the last frame.\nImplementation\n\nConfigure “best effort” reliability mechanism\nConfigure Quality of service history to keep last frame\n\n<reliability>\n  <kind>BEST_EFFORT</kind>\n</reliability>\n\n<historyQos>\n  <kind>KEEP_LAST</kind>\n  <depth>1</depth>\n</historyQos>\n\n\nROS2 Fine Tuning\n\n\nFastRTPS Reliable Video Streaming¶\nContext\nYou want to transfer video streams in unreliable network settings.\nSolution\nUse a reliable communication mechanism. Use fast response by writer and reader.\nImplementation\n\nConfigure “reliable” reliability mechanism\nConfigure NACK reponse delay and suppression duration of writer to 0\nConfigure heartbeat response delay of reader to 0\n\n<reliability>\n  <kind>RELIABLE</kind>\n</reliability>\n\n# writer\n<times>\n  <nackResponseDelay>\n    <durationbyname>ZERO</durationbyname>\n  </nackResponseDelay>\n  <nackSupressionDuration>\n    <durationbyname>ZERO</durationbyname>\n  </nackSupressionDuration>\n</times>\n\n# reader\n<times>\n  <heartbeatResponseDelay>\n    <durationbyname>ZERO</durationbyname>\n  </heartbeatResponseDelay>\n</times>\n\n\nROS2 Fine Tuning\n\n\n"},{"id":28,"url":"/doc/ros2/Tutorials/Eclipse-Oxygen-with-ROS-2-and-rviz2/","title":"Eclipse Oxygen with ROS 2 and rviz2 [community-contributed]","content":"\nEclipse Oxygen with ROS 2 and rviz2 [community-contributed]¶\n\nTable of Contents\n\nSetup\nEclipse-indexer\nDebugging with eclipse\n\n\n\nSetup¶\nWe have installed eclipse Oxygen and git. eclipse-git (Egit) is already installed (http://www.eclipse.org/egit/download/).\nWe call the eclipse-workspace the same name as the ros2 package. This is not needed.\nHINT: We use nested projects and so using one eclipse-workspace for one ROS-2 package, because there are many projects inside even if its one ROS-2 project, it seemed more “clean”.\n\nWe create a C++ Project\n\n\nWe choose as Project-name the name of the ROS 2 package. Makefile Project and Other Toolchain.\n\nThen we click on Finish\n\nIn the “Project explorer” we see our Project.\n\nInside our Project we create a folder called “src”\n\nNow we import a git repository\n\nWe put in the repository URL\n\nIMPORTANT: As destination-folder for the git-repository we use the src-folder of our project we created before.\nHINT: If you got problems choosing the destination folder path, the eclipse-dialog needs a name in the name field.\n\nImport using the new project wizard\n\nWe create a General->Project\n\nUse as project name the same name as the git-repository. This is not needed.\nIMPORTANT: Use as “Location” the folder we cloned the git repository in.\n\nNow we see the git-project and our project in the Project-Explorer view. We see the same files two times, but only one project is linked with Egit.\n\nWe repeat this procedure again. Import git repository pluginlib\n\nIMPORTANT: As “Destination->Directory” we use a folder inside the src-folder.\n\nIMPORTANT: As location for our new project we use the folder we cloned the git repository in\n\nThe same procedure again. Now with tinyxml2_vendor git repository.\n\nIMPORTANT: Again we use a folder inside the src-folder\n\nIMPORTANT: Use as new project folder the location of the folder we cloned.\n\nNow we see all 4 Projects in the Project-Explorer view.\n\nIf we click in the top-right-corner of the Project-Explorer view we can change the Project-Presentation to Hirachical view. Now it looks like a ROS-2 project as it is on hard-drive. But this view is not good, as the linkage to Egit gets lost. So use the Flat Project-Presentation. The Egit linkage is good if you want to see e.g. which author wrote which code-line, etc.\n\nWe go to “C/C++ build”-section and put “ament” into “Build command”\n\nGo to “Behavior” tab and unselect “clean” and put “build” into Build textbox.\n\nBefore you can “Build Project” you need to close eclipse. Open a shell and source the ROS-2 setup.bash file, then cd into the directory of the eclipse project (here: /home/ubu/rviz2_ws/rviz2_ws) and start eclipse from inside this directory.\n\nNow you can use code-completion, egit annotations, eclipse C/C++ Tools, etc.\n\n\n\nEclipse-indexer¶\nIf you open e.g. main.cpp of rviz2 you will perhaps see alot of “unresolved inclusion”.You need todo the following that they disappear and that right-click->Open-Declaration will fully work. Goto Project->Properties->C++General->Path-and-Symbols and to tab References and select “ros2_ws”.\nIMPORTANT: If you have different eclipse-workspaces for ros2_ws and e.g. rviz2_ws, you can add your ros2_ws the same way as later the qt5 directory get added. Hint: Just add the src folder, e.g. /home/ros/ros2_ws/ros2_ws/src  not the build and install directories.\n\nGoto C/C++-General->Path-and-Symbols to tab “Source locations” and click on “Link folder”. There choose the location of qt5 includes.\n\nthen you see something like the next image. You could also add “excludes” (filters) to the added source locations, so that some directories dont get indexed. Its good for the “build” and “install” directories in the rviz2_ws which include duplicate headers.\n\nGoto C++General->Preprocessor includes, select CDT-GCC-Built-in-compiler-settings[shared] and enter into the text-box “command to get compiler specs” the following\n-std=c++14\n\n\n\nThen goto “C/C++-General->Indexer” and select the following in the image. E.g “index unused headers as c files” is to resolve e.g. QApplication, because the QApplication headers content is only “#include “qapplication.h”.\n\nAfter running the indexer (which happens later,so you will see this also later), you can see what it added\n\nAfter that right-click on the rviz2 project and select “Indexer->Rebuild”, after that, you see down-right a progress, you will see that it can resolve all includes.\n\n\n\nDebugging with eclipse¶\nGoto “C/C++-Build” and add to the build command\n-DCMAKE_BUILD_TYPE=Debug\n\n\n\nThen in eclipse goto “Run->Debug Configurations” and add the following and click on “Debug”\n\n\n\n"},{"id":29,"url":"/doc/ros2/Tutorials/Intra-Process-Communication/","title":"Efficient intra-process communication","content":"\nEfficient intra-process communication¶\n\nTable of Contents\n\nBackground\nBuild the demos\nRunning and understanding the demos\nLooking forward\n\n\n\nBackground¶\nROS applications typically consist of a composition of individual “nodes” which perform narrow tasks and are decoupled from other parts of the system.\nThis promotes fault isolation, faster development, modularity, and code reuse, but it often comes at the cost of performance.\nAfter ROS 1 was initially developed, the need for efficient composition of nodes became obvious and Nodelets were developed.\nIn ROS 2 we aim to improve on the design of Nodelets by addressing some fundamental problems that required restructuring of nodes.\nIn this demo we’ll be highlighting how nodes can be composed manually, by defining the nodes separately but combining them in different process layouts without changing the node’s code or limiting its abilities.\n\n\nBuild the demos¶\nThese demos should work on any of the three major OSs (Windows, Mac, or Linux).\nSome of them do require OpenCV to have been installed.\n\nUsing the pre-built binaries¶\nIf you’ve installed the binaries, simply source the ROS 2 setup file and then skip down to any of the individual demos to see how to run them.\n\n\nBuilding from source¶\nMake sure you have OpenCV installed and then follow the source instructions.\nYou can find the from source instructions linked from the main ros2 installation page.\nOnce built source the setup file and continue down to one of the specific demos to read about them and for instructions on how to run them.\n\n\n\nRunning and understanding the demos¶\nThere are a few different demos: some are toy problems designed to highlight features of the intra process communications functionality and some are end to end examples which use OpenCV and demonstrate the ability to recombine nodes into different configurations.\n\nThe two node pipeline demo¶\nThis demo is designed to show that the intra process publish/subscribe connection can result in zero-copy transport of messages when publishing and subscribing with std::unique_ptrs.\nFirst let’s take a look at the source:\nhttps://github.com/ros2/demos/blob/master/intra_process_demo/src/two_node_pipeline/two_node_pipeline.cpp\n#include <chrono>\n#include <cinttypes>\n#include <cstdio>\n#include <memory>\n#include <string>\n\n#include \"rclcpp/rclcpp.hpp\"\n#include \"std_msgs/msg/int32.hpp\"\n\nusing namespace std::chrono_literals;\n\n// Node that produces messages.\nstruct Producer : public rclcpp::Node\n{\n  Producer(const std::string & name, const std::string & output)\n  : Node(name, \"\", true)\n  {\n    // Create a publisher on the output topic.\n    pub_ = this->create_publisher<std_msgs::msg::Int32>(output, rmw_qos_profile_default);\n    std::weak_ptr<std::remove_pointer<decltype(pub_.get())>::type> captured_pub = pub_;\n    // Create a timer which publishes on the output topic at ~1Hz.\n    auto callback = [captured_pub]() -> void {\n        auto pub_ptr = captured_pub.lock();\n        if (!pub_ptr) {\n          return;\n        }\n        static int32_t count = 0;\n        std_msgs::msg::Int32::UniquePtr msg(new std_msgs::msg::Int32());\n        msg->data = count++;\n        printf(\n          \"Published message with value: %d, and address: 0x%\" PRIXPTR \"\\n\", msg->data,\n          reinterpret_cast<std::uintptr_t>(msg.get()));\n        pub_ptr->publish(msg);\n      };\n    timer_ = this->create_wall_timer(1s, callback);\n  }\n\n  rclcpp::Publisher<std_msgs::msg::Int32>::SharedPtr pub_;\n  rclcpp::TimerBase::SharedPtr timer_;\n};\n\n// Node that consumes messages.\nstruct Consumer : public rclcpp::Node\n{\n  Consumer(const std::string & name, const std::string & input)\n  : Node(name, \"\", true)\n  {\n    // Create a subscription on the input topic which prints on receipt of new messages.\n    sub_ = this->create_subscription<std_msgs::msg::Int32>(\n      input, [](std_msgs::msg::Int32::UniquePtr msg) {\n      printf(\n        \" Received message with value: %d, and address: 0x%\" PRIXPTR \"\\n\", msg->data,\n        reinterpret_cast<std::uintptr_t>(msg.get()));\n    }, rmw_qos_profile_default);\n  }\n\n  rclcpp::Subscription<std_msgs::msg::Int32>::SharedPtr sub_;\n};\n\nint main(int argc, char * argv[])\n{\n  setvbuf(stdout, NULL, _IONBF, BUFSIZ);\n  rclcpp::init(argc, argv);\n  rclcpp::executors::SingleThreadedExecutor executor;\n\n  auto producer = std::make_shared<Producer>(\"producer\", \"number\");\n  auto consumer = std::make_shared<Consumer>(\"consumer\", \"number\");\n\n  executor.add_node(producer);\n  executor.add_node(consumer);\n  executor.spin();\n  return 0;\n}\n\n\nAs you can see by looking at the main function, we have a producer and a consumer node, we add them to a single threaded executor, and then call spin.\nIf you look at the “producer” node’s implementation in the Producer struct, you can see that we have created a publisher which publishes on the “number” topic and a timer which periodically creates a new message, prints out its address in memory and its content’s value and then publishes it.\nThe “consumer” node is a bit simpler, you can see its implementation in the Consumer struct, as it only subscribes to the “number” topic and prints the address and value of the message it receives.\nThe expectation is that the producer will print out an address and value and the consumer will print out a matching address and value.\nThis demonstrates that intra process communication is indeed working and unnecessary copies are avoided, at least for simple graphs.\nLet’s run the demo by executing ros2 run intra_process_demo two_node_pipeline executable (don’t forget to source the setup file first):\n$ ros2 run intra_process_demo two_node_pipeline\nPublished message with value: 0, and address: 0x7fb02303faf0\nPublished message with value: 1, and address: 0x7fb020cf0520\n Received message with value: 1, and address: 0x7fb020cf0520\nPublished message with value: 2, and address: 0x7fb020e12900\n Received message with value: 2, and address: 0x7fb020e12900\nPublished message with value: 3, and address: 0x7fb020cf0520\n Received message with value: 3, and address: 0x7fb020cf0520\nPublished message with value: 4, and address: 0x7fb020e12900\n Received message with value: 4, and address: 0x7fb020e12900\nPublished message with value: 5, and address: 0x7fb02303cea0\n Received message with value: 5, and address: 0x7fb02303cea0\n[...]\n\n\nOne thing you’ll notice is that the messages tick along at about one per second.\nThis is because we told the timer to fire at about once per second.\nAlso you may have noticed that the first message (with value 0) does not have a corresponding “Received message …” line.\nThis is because publish/subscribe is “best effort” and we do not have any “latching” like behavior enabled.\nThis means that if the publisher publishes a message before the subscription has been established, the subscription will not receive that message.\nThis race condition can result in the first few messages being lost.\nIn this case, since they only come once per second, usually only the first message is lost.\nFinally, you can see that “Published message…” and “Received message …” lines with the same value also have the same address.\nThis shows that the address of the message being received is the same as the one that was published and that it is not a copy.\nThis is because we’re publishing and subscribing with std::unique_ptrs which allow ownership of a message to be moved around the system safely.\nYou can also publish and subscribe with const & and std::shared_ptr, but zero-copy will not occur in that case.\n\n\nThe cyclic pipeline demo¶\nThis demo is similar to the previous one, but instead of the producer creating a new message for each iteration, this demo only ever uses one message instance.\nThis is achieved by creating a cycle in the graph and “kicking off” communication by externally making one of the nodes publish before spinning the executor:\nhttps://github.com/ros2/demos/blob/master/intra_process_demo/src/cyclic_pipeline/cyclic_pipeline.cpp\n#include <chrono>\n#include <cinttypes>\n#include <cstdio>\n#include <memory>\n#include <string>\n\n#include \"rclcpp/rclcpp.hpp\"\n#include \"std_msgs/msg/int32.hpp\"\n\nusing namespace std::chrono_literals;\n\n// This node receives an Int32, waits 1 second, then increments and sends it.\nstruct IncrementerPipe : public rclcpp::Node\n{\n  IncrementerPipe(const std::string & name, const std::string & in, const std::string & out)\n  : Node(name, \"\", true)\n  {\n    // Create a publisher on the output topic.\n    pub = this->create_publisher<std_msgs::msg::Int32>(out, rmw_qos_profile_default);\n    std::weak_ptr<std::remove_pointer<decltype(pub.get())>::type> captured_pub = pub;\n    // Create a subscription on the input topic.\n    sub = this->create_subscription<std_msgs::msg::Int32>(\n      in, [captured_pub](std_msgs::msg::Int32::UniquePtr msg) {\n      auto pub_ptr = captured_pub.lock();\n      if (!pub_ptr) {\n        return;\n      }\n      printf(\n        \"Received message with value:         %d, and address: 0x%\" PRIXPTR \"\\n\", msg->data,\n        reinterpret_cast<std::uintptr_t>(msg.get()));\n      printf(\"  sleeping for 1 second...\\n\");\n      if (!rclcpp::sleep_for(1s)) {\n        return;    // Return if the sleep failed (e.g. on ctrl-c).\n      }\n      printf(\"  done.\\n\");\n      msg->data++;    // Increment the message's data.\n      printf(\n        \"Incrementing and sending with value: %d, and address: 0x%\" PRIXPTR \"\\n\", msg->data,\n        reinterpret_cast<std::uintptr_t>(msg.get()));\n      pub_ptr->publish(msg);    // Send the message along to the output topic.\n    }, rmw_qos_profile_default);\n  }\n\n  rclcpp::Publisher<std_msgs::msg::Int32>::SharedPtr pub;\n  rclcpp::Subscription<std_msgs::msg::Int32>::SharedPtr sub;\n};\n\nint main(int argc, char * argv[])\n{\n  setvbuf(stdout, NULL, _IONBF, BUFSIZ);\n  rclcpp::init(argc, argv);\n  rclcpp::executors::SingleThreadedExecutor executor;\n\n  // Create a simple loop by connecting the in and out topics of two IncrementerPipe's.\n  // The expectation is that the address of the message being passed between them never changes.\n  auto pipe1 = std::make_shared<IncrementerPipe>(\"pipe1\", \"topic1\", \"topic2\");\n  auto pipe2 = std::make_shared<IncrementerPipe>(\"pipe2\", \"topic2\", \"topic1\");\n  rclcpp::sleep_for(1s);  // Wait for subscriptions to be established to avoid race conditions.\n  // Publish the first message (kicking off the cycle).\n  std::unique_ptr<std_msgs::msg::Int32> msg(new std_msgs::msg::Int32());\n  msg->data = 42;\n  printf(\n    \"Published first message with value:  %d, and address: 0x%\" PRIXPTR \"\\n\", msg->data,\n    reinterpret_cast<std::uintptr_t>(msg.get()));\n  pipe1->pub->publish(msg);\n\n  executor.add_node(pipe1);\n  executor.add_node(pipe2);\n  executor.spin();\n  return 0;\n}\n\n\nUnlike the previous demo, this demo uses only one Node, instantiated twice with different names and configurations.\nThe graph ends up being pipe1 -> pipe2 -> pipe1 … in a loop.\nThe line pipe1->pub->publish(msg); kicks the process off, but from then on the messages are passed back and forth between the nodes by each one calling publish within its own subscription callback.\nThe expectation here is that the nodes pass the message back and forth, once a second, incrementing the value of the message each time.\nBecause the message is being published and subscribed to as a unique_ptr the same message created at the beginning is continuously used.\nTo test those expectations, let’s run it:\n% ros2 run intra_process_demo cyclic_pipeline\nPublished first message with value:  42, and address: 0x7fd2ce0a2bc0\nReceived message with value:         42, and address: 0x7fd2ce0a2bc0\n  sleeping for 1 second...\n  done.\nIncrementing and sending with value: 43, and address: 0x7fd2ce0a2bc0\nReceived message with value:         43, and address: 0x7fd2ce0a2bc0\n  sleeping for 1 second...\n  done.\nIncrementing and sending with value: 44, and address: 0x7fd2ce0a2bc0\nReceived message with value:         44, and address: 0x7fd2ce0a2bc0\n  sleeping for 1 second...\n  done.\nIncrementing and sending with value: 45, and address: 0x7fd2ce0a2bc0\nReceived message with value:         45, and address: 0x7fd2ce0a2bc0\n  sleeping for 1 second...\n  done.\nIncrementing and sending with value: 46, and address: 0x7fd2ce0a2bc0\nReceived message with value:         46, and address: 0x7fd2ce0a2bc0\n  sleeping for 1 second...\n  done.\nIncrementing and sending with value: 47, and address: 0x7fd2ce0a2bc0\nReceived message with value:         47, and address: 0x7fd2ce0a2bc0\n  sleeping for 1 second...\n[...]\n\n\nYou should see ever increasing numbers on each iteration, starting with 42… because 42, and the whole time it reuses the same message, as demonstrated by the pointer addresses which do not change, which avoids unnecessary copies.\n\n\nThe image pipeline demo¶\nIn this demo we’ll use OpenCV to capture, annotate, and then view images.\nNote for OS X users: If these examples do not work or you receive an error like ddsi_conn_write failed -1 then you’ll need to increase your system wide UDP packet size:\n$ sudo sysctl -w net.inet.udp.recvspace=209715\n$ sudo sysctl -w net.inet.udp.maxdgram=65500\n\n\nThese changes will not persist after a reboot.\n\nSimple pipeline¶\nFirst we’ll have a pipeline of three nodes, arranged as such: camera_node -> watermark_node -> image_view_node\nThe camera_node reads from camera device 0 on your computer, writes some information on the image and publishes it.\nThe watermark_node subscribes to the output of the camera_node and adds more text before publishing it too.\nFinally, the image_view_node subscribes to the output of the watermark_node, writes more text to the image and then visualizes it with cv::imshow.\nIn each node the address of the message which is being sent, or which has been received, or both, is written to the image.\nThe watermark and image view nodes are designed to modify the image without copying it and so the addresses imprinted on the image should all be the same as long as the nodes are in the same process and the graph remains organized in a pipeline as sketched above.\n\nNote\nOn some systems (we’ve seen it happen on Linux), the address printed to the screen might not change.\nThis is because the same unique pointer is being reused. In this situation, the pipeline is still running.\n\nLet’s run the demo by executing the following executable:\nros2 run intra_process_demo image_pipeline_all_in_one\n\n\nYou should see something like this:\n\nYou can pause the rendering of the image by pressing the spacebar and you can resume by pressing the spacebar again.\nYou can also press q or ESC to exit.\nIf you pause the image viewer, you should be able to compare the addresses written on the image and see that they are the same.\n\n\nPipeline with two image viewers¶\nNow let’s look at an example just like the one above, except it has two image view nodes.\nAll the nodes are still in the same process, but now two image view windows should show up. (Note for OS X users: your image view windows might be on top of each other).\nLet’s run it with the command:\nros2 run intra_process_demo image_pipeline_with_two_image_view\n\n\n\nJust like the last example, you can pause the rendering with the spacebar and continue by pressing the spacebar a second time. You can stop the updating to inspect the pointers written to the screen.\nAs you can see in the example image above, we have one image with all of the pointers the same and then another image with the same pointers as the first image for the first two entries, but the last pointer on the second image is different. To understand why this is happening consider the graph’s topology:\ncamera_node -> watermark_node -> image_view_node\n                              -> image_view_node2\n\n\nThe link between the camera_node and the watermark_node can use the same pointer without copying because there is only one intra process subscription to which the message should be delivered. But for the link between the watermark_node and the two image view nodes the relationship is one to many, so if the image view nodes were using unique_ptr callbacks then it would be impossible to deliver the ownership of the same pointer to both. It can be, however, delivered to one of them. Which one would get the original pointer is not defined, but instead is simply the last to be delivered.\nNote that the image view nodes are not subscribed with unique_ptr callbacks. Instead they are subscribed with const shared_ptrs. This means the system could have delivered the same shared_ptr to both callbacks. Currently the intra process system is not that intelligent and so it stores the message internally as a unique_ptr and copies it into a shared_ptr for each callback until the last one. On the last callback, regardless of the type, the ownership is transferred out of intra process storage and, in the case of the image view, the ownership is moved into a new shared_ptr and delivered. Thus, one of the image view nodes gets a copy and the other gets the original.\n\n\nPipeline with interprocess viewer¶\nOne other important thing to get right is to avoid interruption of the intra process zero-copy behavior when interprocess subscriptions are made. To test this we can run the first image pipeline demo, image_pipeline_all_in_one, and then run an instance of the stand alone image_view_node (don’t forget to prefix them with ros2 run intra_process_demo in the terminal). This will look something like this:\n\nIt’s hard to pause both images at the same time so the images may not line up, but the important thing to notice is that the image_pipeline_all_in_one image view shows the same address for each step. This means that the intra process zero-copy is preserved even when an external view is subscribed as well. You can also see that the interprocess image view has different process IDs for the first two lines of text and the process ID of the standalone image viewer in the third line of text.\n\n\n\n\nLooking forward¶\nThese demos are the foundation for some cool new features on which we’re actively working, but right now some things are missing.\n\nRoom for Improvement¶\nLet’s start by looking at what we at OSRF know we can do better or differently and move on from there.\n\nIntra Process Manager Storage¶\nAt the core of the intra process implementation is something called the intra process manager. It is the shared state between nodes (not necessarily global) which facilitates intra process communication. The intra process manager has a lot of room for improvement, but one thing on our short list is to have it be more intelligent about how to store the user’s data internally. In the example with two image view nodes all in the same process, we could have delivered the user’s provided pointer to both image view nodes as copies of a single shared_ptr. This is possible only because of the intra process graph’s structure, but given any relationship of a publisher to one or more intra process subscriptions there should be a preferred solution.\nFor example, imagine if there was a publisher connected to three intra process subscriptions where one was subscribed as a unique_ptr and the other two were subscribed as a shared_ptr. If you store the the message as a unique_ptr then you must make a copy for each of the shared_ptr but you can deliver to the unique_ptr callback without a copy. But if you instead stored the message as a shared_ptr then you give that shared_ptr to the two shared_ptr callbacks and make one copy for the unique_ptr callback, which would save on copies. In both cases we’ve assumed that only one copy of the message should be stored, i.e. we will not store a unique_ptr of the message as well as a shared_ptr copy. There is a performance trade-off when decided whether to make those copies or not, so one thing to figure out moving forward is how and when to expose this trade-off to the developer.\nThis problem gets more interesting when we start doing Type Masquerading :smile:, which we’ll talk about below.\n\n\nAvoiding Unnecessary Interprocess Publishes¶\nCurrently we’re relying on the middleware, the DDS vendor, to avoid publishing to the wire unnecessarily, but no matter what we have to give the middleware a copy of the user’s message. We could avoid this copy given to the system if we could know if it is needed. We can do this currently by checking to see if there are any non intra process subscriptions currently attached to the publisher. The problem with this becomes apparent when we go to implement latching, which we’ll see more about below.\n\n\nAvoiding Memory Allocation¶\nIn other parts of the system we’ve worked really hard to allow users to avoid memory allocation. This has performance benefits and may be required for real-time or embedded scenarios. We cannot currently do that with intra process. Mostly this is because we haven’t had time to figure out the right interfaces, but the general problem is that if a message needs to be delivered to more than one subscription, or if the user gives us a const & or const shared_ptr when publishing, we need to make a copy. And the destination of the copy is currently created using new and is not configurable. We expect to resolve that in the future.\n\n\nPerformance, Performance, Performance¶\nThis is a very rough first draft. There is a lot of room for improvement, even beyond what has been enumerated above. We’ll start to improve performance as we dig into the details of the system, build up a better understanding of exactly what our middleware vendors are doing, and try alternative strategies for implementing intra process.\n\n\n\nWhat’s Missing¶\nAforementioned are some things we can improve with what’s already there. But there are also some things we’d like to add on top of this that are pretty interesting and some things that are just necessary.\n\nLatching¶\nWe haven’t fully implemented the concept of latching yet, but it’s very likely we’ll need to adjust the implementation of the intra process manager to account for the fact that late intra process subscriptions should be delivered to as well. There are several options on how to do that, and we’ll do some testing and figure out what to do in the near future.\n\n\nBeyond Pub/Sub¶\nWe’ve not done any of this with Services, Parameters, or Actions, but we will.\n\n\nType Masquerading¶\nThis is one of the coolest upcoming features that we didn’t get to in this demo.\nImagine the image pipeline demo above, but rather than passing sensor_msgs/Images around, you’re publishing and subscribing to cv::Mat objects. This exists in ROS 1, see: http://wiki.ros.org/roscpp/Overview/MessagesSerializationAndAdaptingTypes\nIn ROS 1, this is accomplished by serializing/deserializing the third party type when handling it. This means that with intra process you’ll be serializing when passing it between nodelets. But in ROS 2 we want to do it in the most performant way possible. Similar to how these demos have been demonstrating that an instance of a message can be used through the whole pipeline in certain cases, we’d like to do the same with third party types. So conceivably you could have the image pipeline with a single cv::Mat which never gets copied by the middleware. To do this requires some additional intelligence in the intra process manager, but we’ve already got a design and some proof of concepts in the works.\nGiven these features, hopefully there will come a point where you can trust the middleware to handle your data as efficiently as is possible. This will allow you to write performant algorithms without sacrificing modularity or introspection!\n\n\nTooling¶\nOne of the sticking points of Nodelets in ROS 1 was the complexity of defining, building, and using them.\nWe’ve not tackled that problem yet, but we are working on it. We’ve got a port of class loader (https://github.com/ros/class_loader/tree/ros2) and pluginlib (https://github.com/ros/pluginlib/tree/ros2) for ROS 2, but we only have prototypes of the CMake infrastructure which will help users build and run their nodes. Here’s a sketch of the design we expect:\nadd_node(my_node src/my_node.cpp)\ntarget_link_libraries(my_node ${external_dependency_LIBRARIES} ...)\n\n\nWe’ll provide an interface similar to CMake’s add_executable or add_library. This doesn’t preclude the idea of providing a more automatic solution a la ament_cmake_auto.\nThis simple CMake entry will generate a few things:\n\nA marker file used to discover the node by pluginlib.\nA shared library for your node.\nAn executable for your node.\n\nThe executable can run the node in its own process, or serve as a proxy while the node runs in a different container.\n\n\n\nWe’ll also need to develop the container, which can run nodes inside of itself and is controlled externally by ROS primitives like Services.\nWe’ve got a lot of work to do, but hopefully this tutorial gives you a sense of where we’re going and what we’re trying to do in terms of performance and features.\n\n\n\n\n"}]